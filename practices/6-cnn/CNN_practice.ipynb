{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN practice.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Xeapf_vYGl80",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import resnet34\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GpHmo0BG2SX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сегодня мы будем использовать transfer learning чтобы обучить классификатор героев классических звёздных войн. Эта практика требует обучения на GPU (иначе код будет выполнятся очень долго), поэтому используйте https://colab.research.google.com.\n",
        "\n",
        "Сначала нужно включить поддержку GPU. Зайдите в Edit -> Notebook settings и как hardware accelerator укажите GPU."
      ]
    },
    {
      "metadata": {
        "id": "K9HRimYvHWJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь нужно скачать данные, выполните следующую ячейку.\n",
        "В первый раз она попросит вас перейти по ссылке - откройте эту ссылку и скопируйте оттуда токен (длинную строку в base64), вставьте этот токен в окошко под ячейкой."
      ]
    },
    {
      "metadata": {
        "id": "glyFL0_dHknT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_data(file_id, file_name):\n",
        "  import io\n",
        "  from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "  request = drive_service.files().get_media(fileId=file_id)\n",
        "  downloaded = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(downloaded, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "    \n",
        "  downloaded.seek(0)\n",
        "  with open(file_name, \"wb\") as f:\n",
        "    f.write(downloaded.read())\n",
        "\n",
        "  \n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "file_id = '139wA_Z9kustXy54ifhWWHJvARo5f7O6y'\n",
        "file_name = 'star_wars.tar.gz'\n",
        "\n",
        "download_data(file_id, file_name)\n",
        "!tar xf star_wars.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9msPyG3H_Rz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Важная часть обучения нейронных сетей (как и обычно в машинном обучении)  - это работа с данными. Необходимо представить данные в векторном виде и отдать их модели для обучения. В фреймворке Pytorch для этого используется связка двух классов: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset и https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader. \n",
        "\n",
        "Первый это даже не класс, а интерфейс - у него всего два интересных метода:\n",
        "__getitem__ - выбрать из датасета элемент по заданному числовому индексу\n",
        "__len__ - вернуть длину датасета.\n",
        "\n",
        "\n",
        "\n",
        "DataLoader в свою очередь занимается тем что выбирает элементы из Dataset который передается ему в конструкторе и делает из них батчи для обучения нейронной сети. Вы можете контролировать размер батча с помощью параметра batch_size, также не забудьте включать перемешивание данных перед каждой эпохой передавая в DataLoader параметр shuffle=True. В более продвинутых случаях возможно задавать стратегию того как именно конструируются батчи с помощью классов Sampler и BatchSampler, но мы в нашей практике этих возможностей касаться не будем.\n",
        "\n",
        "Главное отличие Dataset от массива на практике в том что этот интерфейс не обязывает вас хранить весь набор данных в памяти. Типичная реализация по индексу подгружает данные с диска и делает из них сэмпл. "
      ]
    },
    {
      "metadata": {
        "id": "ZwcKwd3-pxmR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Я создал 4 папки и скачал в них картинки с помощью https://github.com/hardikvasa/google-images-download\n",
        "\n",
        "Это делается очень просто:\n",
        "\n",
        "```\n",
        "pip install google_images_download\n",
        "googleimagesdownload -k \"люк скайуокер\"\n",
        "```\n",
        "Гугл ограничивает количество картинок, которые можно скачать по поисковому запросу, но это можно обойти либо скачивать с других мест, где нет ограничений (напр. Yandex или Instagram)\n",
        "\n",
        "\n",
        "В итоге у нас получилась следующая структура на диске:\n",
        "\n",
        "```\n",
        "root/люк скайуокер/xxx.jpg\n",
        "root/люк скайуокер/xxy.jpeg\n",
        "root/люк скайуокер/xxz.png\n",
        "\n",
        "root/чубакка/123.png\n",
        "root/чубакка/nsdf3.jpg\n",
        "root/чубакка/asd932_.gif\n",
        "```\n",
        "\n",
        "По сколько это просто выдача гугла, тут встречаются как .jpg и .png так и .gif\n",
        "\n",
        "Удобнее всего (по крайней мере мне), когда у вас есть 2 массива - один с путями к файлам и другой с лейблами для них. Давайте я сделаю его за вас:"
      ]
    },
    {
      "metadata": {
        "id": "2jILbuZ9qQax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filenames = []\n",
        "labels = []\n",
        "for idx, class_dir in enumerate(os.listdir(\"star_wars\")):\n",
        "  print(f\"берем файлы из папки \\\"{class_dir}\\\" и даем им класс {idx}\")\n",
        "  \n",
        "  # не берем файлы кроме .jpg .jpeg и .png\n",
        "  for file in os.listdir(os.path.join(\"star_wars\", class_dir)):\n",
        "    if not file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "      continue\n",
        "      \n",
        "    filenames.append(os.path.join(\"star_wars\", class_dir, file))\n",
        "    labels.append(idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MVzPQD5iqRFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Это типичная ситуация, как у вас могут оказаться данные на руках (а не непонятный массив как было c MNIST)"
      ]
    },
    {
      "metadata": {
        "id": "eQZki--DzLqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# будем брать по 1 рандомной картинке, выводить ее и смотреть на класс. Так в реально жизни можно проверить не *** ли вы скачали и верные ли классы\n",
        "# можете выполнять этот cell пока не надоест\n",
        "random_index = np.random.choice(range(len(filenames)))\n",
        "test_img = cv2.imread(filenames[random_index])[:, :, ::-1] # эта штука в конце равносильно переводу из BGR в RGB\n",
        "print(labels[random_index])\n",
        "plt.imshow(test_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGH-FQtAqkU1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Задание 1. Разбейте filenames и labels на train и test части 70/30\n",
        "train_filenames, test_filenames, train_labels, test_labels = "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8Ny_q5lKs8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь нашей основной задачей является создание Dataset и Dataloader для наших данных. Их должно быть два: один для train, другой для test.\n",
        "\n",
        "Мы собираемся использовать transfer learning - взять сеть предобученную на ImageNet и доучить её на наших изображениях. Сети тренировавшиеся на ImageNet требуют стандартного размера картинок: 224x224.\n",
        "\n",
        "Нам нужно поресайзить картинки и делать их квадратными. Я подготовил вам два метода для ресайза и для добавление 'ушей' к изображению если оно не квадратное. Вы должны поюзать их в своем классе Dataset. "
      ]
    },
    {
      "metadata": {
        "id": "3_YoePxsr7ig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_pad(img, shape):\n",
        "    color_pick = img[0][0]\n",
        "    padded_img = color_pick * np.ones(shape + img.shape[2:3], dtype=np.uint8)\n",
        "    x_offset = int((padded_img.shape[0] - img.shape[0]) / 2)\n",
        "    y_offset = int((padded_img.shape[1] - img.shape[1]) / 2)\n",
        "    padded_img[x_offset:x_offset + img.shape[0], y_offset:y_offset + img.shape[1]] = img\n",
        "\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def resize(img, shape):\n",
        "    scale = min(shape[0] * 1.0 / img.shape[0], shape[1] * 1.0 / img.shape[1])\n",
        "    if scale != 1:\n",
        "        img = cv2.resize(img, dsize=None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p__lNU_4Kqca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Задание 2. Реализуйте класс-наследник Dataset. Он должен возвращать по индексу \n",
        "class StarWarsDataset(Dataset):\n",
        "    def __init__(self, filenames, labels):\n",
        "        # something here\n",
        "        # something here\n",
        "\n",
        "    def __len__(self):\n",
        "        return # something here\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # dataloader запросит какой-то индекс (но не больше чем значение __len__)\n",
        "        # мы должны отдать ему image в виде массива и соотвуствующий ему label\n",
        "        filename = self._filenames[idx]\n",
        "        label = # something here\n",
        "        \n",
        "        # мы получили имя файла, теперь нужно загрузить картинку как numpy array \n",
        "        # и изменить размер так, чтобы он был 224 на 224\n",
        "        img = cv2.imread #.... something here\n",
        "        \n",
        "        img = # use resize here\n",
        "        img = # use add pad here\n",
        "        \n",
        "        # меняем порядок каналов и делим все на 255, оборачиваем в torch tensor\n",
        "        # это просто надо делать, потом спросите зачем\n",
        "        img = torch.tensor(img, dtype=torch.float).permute(2, 0, 1) / 255.\n",
        "        return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yX6fprMHMBco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Мы написали типичный класс-наследник Dataset для данных такого формата и поресайзили изображение к размеру 224х224 + преобразовали его в тензор внутри него. Теперь нужно создать Dataloader - да штука, которая просит возвращать Dataset данные по idx и составляет их них батчи."
      ]
    },
    {
      "metadata": {
        "id": "qiA_x5uatT_G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = StarWarsDataset(train_fns, train_lbls)\n",
        "train_dataloder = DataLoader(train_dataset, shuffle=True, batch_size=64, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0F6K3e4tZee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Задание 3. Сделайте dataloader для test\n",
        "test_dataset = # something here\n",
        "test_dataloder = # something here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11joHOfxtodx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Завайте посмотрим что выводит ваш тестовый Dataloader..."
      ]
    },
    {
      "metadata": {
        "id": "YwAwwPWfttX4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for batch in test_dataloder: # получаем 1 batch - 1 итерация подгрузки данных\n",
        "  images, labels = batch     # наш Dataset возвращает tuple, поэтому мы можем сделать так\n",
        "  print(f'Всего батчей по batch_size: {len(train_dataloder)}')\n",
        "  print(f'Лейбл первого элемента в первом батче: {labels[0]}')\n",
        "  print(f'Размер картинки в первом батче: {images[0].shape}')\n",
        "  print(f'Картинка в первом батче: {images[0]}')\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n1QgZzKgRagH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Здесь мы берем предобученный resnet34 и заменяем в нём последний слой на голову классифицирующую изображение на 1 из 4 классов\n",
        "# Берём кросс энтропию в качестве лосса и оптимизатор адам\n",
        "# Мы замораживаем все слои сети кроме последнего, который будем обучать далее\n",
        "\n",
        "model = resnet34(pretrained=True) # resnet обученный на ImageNet\n",
        "for param in model.parameters():\n",
        "  param.requires_grad=False\n",
        "\n",
        "# loss и optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TdrjlKs8vqdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# можно принтануть модель и уведеть какие в ней слои\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSeMn3OcwZs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Как я и говорил, transfer learning - это очень просто. В resnet куча сверток и пулингов, в конце fully connected слой на 1000. Мы удаляет последний слой, заменяя его новым на с выходом на 4 класса. Так, свертки внутри модели помнят все фичи умеют распознавать классы из ImageNet, мы просто помогаем их скорректировать на наших данных  "
      ]
    },
    {
      "metadata": {
        "id": "GRyrHN9fvxV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 4)\n",
        "model.to('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNNJdU2QRse4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Эта функция считает точность модели - на вход передается сама модель, номер эпохи и тестовый лоадер.\n",
        "\n",
        "def run_test_on_epoch(model, epoch, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_accuracy = []\n",
        "      test_real = []\n",
        "      for batch_x, batch_y in tqdm(test_loader):\n",
        "          outputs = model(batch_x.to('cuda')).detach().cpu().numpy()\n",
        "          test_accuracy.append(outputs)\n",
        "          test_real.append(batch_y.detach().cpu().numpy())\n",
        "      print(\"Epoch\", epoch, \"test accuracy\", accuracy_score(np.hstack(test_real), np.argmax(np.hstack(test_accuracy), axis=1)))\n",
        "    model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GY3ofh1SSAec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Задание 5. Напишите код для обучения модели 25 эпох. В конце каждой эпохи вызывайте run_test_on_epoch() чтобы следить за точностью\n",
        "for epoch in tqdm(range(25)):\n",
        "  # что-то очень важное здесь\n",
        "  # строчек 6 примерно\n",
        "  \n",
        "  \n",
        "  # половину сделал за вас\n",
        "  run_test_on_epoch(model, epoch, test_dataloder)\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zq093_VVSaBG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Какая точность у вас получилась?\n",
        "\n",
        "Дополнительные задания:\n",
        " 1. Скачать свои данные и обучить на них\n",
        " 2. Добавить агументации в класс StarWarsDataset (например, не только resize и add_pad а конвертацию в grayscale в 10% случаях или сглаживание)"
      ]
    }
  ]
}